{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "########################################################################\n",
    "# Python Standard Libraries\n",
    "import os\n",
    "import multiprocessing\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "########################################################################\n",
    "# Numpy Library\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "########################################################################\n",
    "# Pandas Library\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "########################################################################\n",
    "# MATPLOT Library\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "########################################################################\n",
    "# SKLearn Library\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, classification_report, confusion_matrix, average_precision_score, roc_curve, auc, multilabel_confusion_matrix\n",
    "\n",
    "########################################################################\n",
    "# SCIPY Library\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM:                   18.621841 GB\n",
      "CORES:                 4\n",
      "Architecture:        x86_64\r\n",
      "CPU op-mode(s):      32-bit, 64-bit\r\n",
      "Byte Order:          Little Endian\r\n",
      "CPU(s):              4\r\n",
      "On-line CPU(s) list: 0-3\r\n",
      "Thread(s) per core:  2\r\n",
      "Core(s) per socket:  2\r\n",
      "Socket(s):           1\r\n",
      "NUMA node(s):        1\r\n",
      "Vendor ID:           GenuineIntel\r\n",
      "CPU family:          6\r\n",
      "Model:               79\r\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
      "Stepping:            0\r\n",
      "CPU MHz:             2200.000\r\n",
      "BogoMIPS:            4400.00\r\n",
      "Hypervisor vendor:   KVM\r\n",
      "Virtualization type: full\r\n",
      "L1d cache:           32K\r\n",
      "L1i cache:           32K\r\n",
      "L2 cache:            256K\r\n",
      "L3 cache:            56320K\r\n",
      "NUMA node0 CPU(s):   0-3\r\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n"
     ]
    }
   ],
   "source": [
    "# Utility functions\n",
    "########################################################################\n",
    "# Print system information\n",
    "def print_system_info():\n",
    "    mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n",
    "    mem_gib = mem_bytes/(1024.**3)  # e.g. 3.74\n",
    "    print(\"{:<23}{:f} GB\".format('RAM:', mem_gib))\n",
    "    print(\"{:<23}{:d}\".format('CORES:', multiprocessing.cpu_count()))\n",
    "    !lscpu\n",
    "\n",
    "########################################################################\n",
    "# Walk through input files\n",
    "def print_input_files():\n",
    "    # Input data files are available in the \"../input/\" directory.\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "########################################################################\n",
    "# Dump text files\n",
    "def dump_text_file(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "########################################################################\n",
    "# Dump CSV files\n",
    "def dump_csv_file(fname, count=5):\n",
    "    # count: 0 - column names only, -1 - all rows, default = 5 rows max\n",
    "    df = pd.read_csv(fname)\n",
    "    if count < 0:\n",
    "        count = df.shape[0]\n",
    "    return df.head(count)\n",
    "\n",
    "########################################################################\n",
    "# Dataset related functions\n",
    "ds_nbaiot = '/kaggle/input/nbaiot-dataset'\n",
    "dn_nbaiot = ['Danmini_Doorbell', 'Ecobee_Thermostat', 'Ennio_Doorbell', 'Philips_B120N10_Baby_Monitor', 'Provision_PT_737E_Security_Camera', 'Provision_PT_838_Security_Camera', 'Samsung_SNH_1011_N_Webcam', 'SimpleHome_XCS7_1002_WHT_Security_Camera', 'SimpleHome_XCS7_1003_WHT_Security_Camera']\n",
    "\n",
    "def fname(ds, f):\n",
    "    if '.csv' not in f:\n",
    "        f = f'{f}.csv'\n",
    "    return os.path.join(ds, f)\n",
    "\n",
    "def fname_nbaiot(f):\n",
    "    return fname(ds_nbaiot, f)\n",
    "\n",
    "def get_nbaiot_device_files():\n",
    "    nbaiot_all_files = dump_csv_file(fname_nbaiot('data_summary'), -1)\n",
    "    nbaiot_all_files = nbaiot_all_files.iloc[:,0:1].values\n",
    "    device_id = 1\n",
    "    indices = []\n",
    "    for j in range(len(nbaiot_all_files)):\n",
    "        if str(device_id) not in str(nbaiot_all_files[j]):\n",
    "            indices.append(j)\n",
    "            device_id += 1\n",
    "    nbaiot_device_files = np.split(nbaiot_all_files, indices)\n",
    "    return nbaiot_device_files\n",
    "\n",
    "def get_nbaiot_device_data(device_id, count_norm=-1, count_anom=-1):\n",
    "    if device_id < 1 or device_id > 9:\n",
    "        assert False, \"Please provide a valid device ID 1-9, both inclusive\"\n",
    "    if count_anom == -1:\n",
    "        count_anom = count_norm\n",
    "    device_index = device_id -1\n",
    "    device_files = get_nbaiot_device_files()\n",
    "    device_file = device_files[device_index]\n",
    "    df = pd.DataFrame()\n",
    "    y = []\n",
    "    for i in range(len(device_file)):\n",
    "        fname = str(device_file[i][0])\n",
    "        df_c = pd.read_csv(fname_nbaiot(fname))\n",
    "        count = count_anom\n",
    "        if 'benign' in fname:\n",
    "            count = count_norm\n",
    "        rows = count if count >=0 else df_c.shape[0]\n",
    "        print(\"processing\", fname, \"rows =\", rows)\n",
    "        y_np = np.ones(rows) if 'benign' in fname else np.zeros(rows)\n",
    "        y.extend(y_np.tolist())\n",
    "        df = pd.concat([df.iloc[:,:].reset_index(drop=True),\n",
    "                      df_c.iloc[:rows,:].reset_index(drop=True)], axis=0)\n",
    "    X = df.iloc[:,:].values\n",
    "    y = np.array(y)\n",
    "    Xdf = df\n",
    "    return (X, y, Xdf)\n",
    "\n",
    "def get_nbaiot_devices_data():\n",
    "    devices_data = []\n",
    "    for i in range(9):\n",
    "        device_id = i + 1\n",
    "        (X, y) = get_nbaiot_device_data(device_id)\n",
    "        devices_data.append((X, y))\n",
    "    return devices_data\n",
    "#print_input_files()\n",
    "print_system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, threshold):\n",
    "    df = df.copy()\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find features with correlation greater than a threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "    # Drop features \n",
    "    df.drop(to_drop, axis=1, inplace=True)\n",
    "    return df.iloc[:,:].values\n",
    "\n",
    "def mark_important_features(vector, pc_keep): # pc_keep is the percentage (0-100) of labels to keep\n",
    "    th = np.percentile(vector,(100-pc_keep)) # threshold, calculate percentile (100 - percentage) from percentage\n",
    "    important_bool = (vector >= th)\n",
    "    important_int = important_bool.astype(int)\n",
    "    return important_int\n",
    "\n",
    "def select_features(X, y, threshold):\n",
    "    indices_norm = np.where(y >= 0.5)\n",
    "    indices_anom = np.where(y <= 0.5)\n",
    "    X_norm = X[indices_norm]\n",
    "    X_anom = X[indices_anom]\n",
    "\n",
    "    rows_n = X_norm.shape[0]\n",
    "    rows_a = X_anom.shape[0]\n",
    "    if rows_n == 0 or rows_a == 0:\n",
    "        return X\n",
    "\n",
    "    y_norm = np.ones(rows_n)\n",
    "    y_anom = -1 * np.ones(rows_a)\n",
    "\n",
    "    reg_n = LinearRegression(fit_intercept=False)\n",
    "    reg_n.fit(X_norm, y_norm)\n",
    "    coef_n = abs(reg_n.coef_)\n",
    "    n = mark_important_features(coef_n, threshold)\n",
    "\n",
    "    reg_a = LinearRegression(fit_intercept=False)\n",
    "    reg_a.fit(X_anom, y_anom)\n",
    "    coef_a = abs(reg_a.coef_)\n",
    "    a = mark_important_features(coef_a, threshold)\n",
    "   \n",
    "    mask = np.bitwise_or(n,a)\n",
    "    mask = mask == 1 # convert to Boolean\n",
    "    X_sel = X[:, mask]\n",
    "    return X_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_teda_obj(observation, k=None, mean=None, var=None, ecc=None):\n",
    "    teda = {}\n",
    "    if not k:\n",
    "        k = 1\n",
    "        mean = observation\n",
    "        var = 0\n",
    "        ecc = 1\n",
    "    else:\n",
    "        if mean is None or var is None or ecc is None:\n",
    "            assert False, 'mean, variance and ecc values are required'\n",
    "\n",
    "    teda['k'] = k\n",
    "    teda['observation'] = observation\n",
    "    teda['mean'] = mean\n",
    "    teda['var'] = var\n",
    "    teda['eccentricity'] = ecc\n",
    "    teda['typicality'] = 1.0 - ecc\n",
    "    teda['norm_eccentricity'] = teda['eccentricity'] / 2.0\n",
    "    teda['norm_typicality'] = teda['typicality'] / (k - 2.0)\n",
    "    teda['outlier'] = 1.0 if teda['norm_eccentricity'] > (1.0 / k) else 0.0\n",
    "    teda['normal'] = 1.0 if teda['outlier'] < 0.5 else 0.0\n",
    "    teda['normal_bool'] = True if teda['normal'] > 0.5 else False\n",
    "    teda['ecc_threshold'] = 1.0 / k\n",
    "\n",
    "    return teda\n",
    "\n",
    "\n",
    "def calc_teda_single(observation, teda = None):\n",
    "    if not teda:\n",
    "        teda = gen_teda_obj(observation)\n",
    "    else:\n",
    "        k = teda['k'] + 1.0\n",
    "        mean = teda['mean']\n",
    "        var = teda['var']\n",
    "\n",
    "        # Calculate the running mean value\n",
    "        mean =  (((k - 1)  / k) * mean) + ((1 / k) * observation)\n",
    "\n",
    "        # Calculate the running mean value\n",
    "        var = (((k - 1) / k) * var) + (1 / (k - 1)) * np.linalg.norm(observation - mean)\n",
    "\n",
    "        # Calculate the running eccentricity value\n",
    "        ecc = (1 / k) +  (np.linalg.norm(mean - observation) / (k * var))\n",
    "\n",
    "        teda = gen_teda_obj(observation, k, mean, var, ecc)\n",
    "\n",
    "    return teda\n",
    "\n",
    "def calc_teda(X):\n",
    "    teda = None\n",
    "    teda_output = []\n",
    "    rows = X.shape[0]\n",
    "    for i in range(rows):\n",
    "        teda = calc_teda_single(X[i,:], teda)\n",
    "        teda_output.append(teda['normal'])\n",
    "\n",
    "    return teda_output\n",
    "\n",
    "def dytokinesis(X, X_norm, X_anom):\n",
    "    teda_norm = None\n",
    "    teda_anom = None\n",
    "    y_pred = []\n",
    "    rows = X.shape[0]\n",
    "    rows_norm = X_norm.shape[0]\n",
    "    rows_anom = X_anom.shape[0]\n",
    "    for i in range(rows_norm):\n",
    "        teda_norm = calc_teda_single(X_norm[i,:], teda_norm)\n",
    "\n",
    "    for i in range(rows_anom):\n",
    "        teda_anom = calc_teda_single(X_anom[i,:], teda_anom)\n",
    "\n",
    "    for i in range(rows):\n",
    "        teda_norm_tmp = calc_teda_single(X[i,:], teda_norm)\n",
    "        teda_anom_tmp = calc_teda_single(X[i,:], teda_anom)\n",
    "        \n",
    "        if (teda_norm_tmp['normal_bool'] == True):\n",
    "            y_pred.append(1.0)\n",
    "            teda_norm = teda_norm_tmp\n",
    "        else:\n",
    "            y_pred.append(0.0)\n",
    "            teda_anom = teda_anom_tmp\n",
    "\n",
    "    return(np.array(y_pred))\n",
    "\n",
    "class Dytokinesis:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def predict(self, X, X_norm, X_anom):\n",
    "        return dytokinesis(X, X_norm, X_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_to_X_norm_and_X_anom(X,y):\n",
    "    indices_norm = np.where(y >= 0.5)\n",
    "    indices_anom = np.where(y <= 0.5)\n",
    "    X_norm_all = X[indices_norm]\n",
    "    X_anom_all = X[indices_anom]\n",
    "    count_frac = 0.05\n",
    "    count_norm = int(count_frac * float(X_norm_all.shape[0]))\n",
    "    count_anom = int(count_frac * float(X_anom_all.shape[0]))\n",
    "    X_norm = X_norm_all[0:count_norm,:]\n",
    "    X_anom = X_anom_all[0:count_anom,:]\n",
    "    return (X_norm, X_anom)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predit_with_execution_time(X_std, X_norm, X_anom):\n",
    "    start = timer()\n",
    "    dyt = Dytokinesis()\n",
    "    y_pred = dyt.predict(X_std, X_norm, X_anom)\n",
    "    end = timer()\n",
    "    execution_time = end - start\n",
    "    return (execution_time, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrices(X,y):\n",
    "    feature_count = X.shape[1]\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    (X_norm, X_anom) = X_to_X_norm_and_X_anom(X_std, y)\n",
    "    (execution_time, y_pred) = predit_with_execution_time(X_std, X_norm, X_anom)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    return (feature_count, execution_time, acc, tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1.benign.csv rows = 49548\n",
      "processing 1.gafgyt.combo.csv rows = 59718\n",
      "processing 1.gafgyt.junk.csv rows = 29068\n",
      "processing 1.gafgyt.scan.csv rows = 29849\n",
      "processing 1.gafgyt.tcp.csv rows = 92141\n",
      "processing 1.gafgyt.udp.csv rows = 105874\n",
      "processing 1.mirai.ack.csv rows = 102195\n",
      "processing 1.mirai.scan.csv rows = 107685\n",
      "processing 1.mirai.syn.csv rows = 122573\n",
      "processing 1.mirai.udp.csv rows = 237665\n",
      "processing 1.mirai.udpplain.csv rows = 81982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danmini_Doorbell\n",
      "threshold,feature_count,execution_time,acc,tn,fp,fn,tp\n",
      "none,115,87.274137,0.98,968750,0,18460,31088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00,115,86.924511,0.98,968750,0,18460,31088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95,110,86.715546,0.98,968251,499,18645,30903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90,104,86.370265,0.98,967805,945,18800,30748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85,100,86.507783,0.98,967646,1104,18701,30847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80,97,86.411033,0.98,966628,2122,18650,30898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75,93,86.060850,0.98,968396,354,18726,30822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70,86,84.385783,0.98,968729,21,18564,30984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65,83,81.802862,0.98,968730,20,18787,30761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60,81,78.090579,0.98,968730,20,18891,30657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55,76,76.115016,0.98,968733,17,19002,30546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50,73,76.230781,0.98,968734,16,19013,30535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45,71,76.271479,0.98,968734,16,19019,30529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40,69,76.778106,0.98,968734,16,19019,30529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35,63,76.147222,0.98,968732,18,19034,30514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30,55,80.232066,0.98,968731,19,19077,30471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25,49,75.380588,0.98,968729,21,19051,30497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20,39,75.838426,0.98,968729,21,19052,30496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15,32,75.543453,0.98,968729,21,19036,30512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10,20,75.337766,0.98,968158,592,18972,30576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05,8,75.284948,0.75,728720,240030,18955,30593\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    device_index = i\n",
    "    device_id = device_index + 1\n",
    "    device_name = dn_nbaiot[device_index]\n",
    "    (X, y, Xdf) = get_nbaiot_device_data(device_id)\n",
    "    (feature_count, execution_time, acc, tn, fp, fn, tp) = compute_metrices(X, y)\n",
    "    print(device_name)\n",
    "    print(\"threshold,feature_count,execution_time,acc,tn,fp,fn,tp\")\n",
    "    print(f'none,{feature_count},{execution_time:.6f},{acc:.2f},{tn},{fp},{fn},{tp}')\n",
    "    for i in range(20):\n",
    "        j = 100 - (i*5)\n",
    "        threshold = float(j)/100.0\n",
    "        #X_tmp = remove_correlated_features(Xdf, threshold)\n",
    "        X_tmp = select_features(X, y, j)\n",
    "        (feature_count, execution_time, acc, tn, fp, fn, tp) = compute_metrices(X_tmp, y)\n",
    "        print(f'{threshold:.2f},{feature_count},{execution_time:.6f},{acc:.2f},{tn},{fp},{fn},{tp}')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
